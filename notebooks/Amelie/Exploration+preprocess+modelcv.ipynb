{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amateur-metallic",
   "metadata": {},
   "source": [
    "# Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "molecular-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proud-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "challenging-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-insurance",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unsigned-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../raw_data/bitstampUSD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "automatic-hardwood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume_(BTC)</th>\n",
       "      <th>Volume_(Currency)</th>\n",
       "      <th>Weighted_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1325317920</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.39</td>\n",
       "      <td>0.455581</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1325317980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1325318040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1325318100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1325318160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727772</th>\n",
       "      <td>1609372560</td>\n",
       "      <td>28801.47</td>\n",
       "      <td>28829.42</td>\n",
       "      <td>28785.64</td>\n",
       "      <td>28829.42</td>\n",
       "      <td>0.965221</td>\n",
       "      <td>27804.572129</td>\n",
       "      <td>28806.429798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727773</th>\n",
       "      <td>1609372620</td>\n",
       "      <td>28829.42</td>\n",
       "      <td>28863.90</td>\n",
       "      <td>28829.42</td>\n",
       "      <td>28857.06</td>\n",
       "      <td>2.368831</td>\n",
       "      <td>68332.350629</td>\n",
       "      <td>28846.441863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727774</th>\n",
       "      <td>1609372680</td>\n",
       "      <td>28850.49</td>\n",
       "      <td>28900.52</td>\n",
       "      <td>28850.49</td>\n",
       "      <td>28882.82</td>\n",
       "      <td>2.466590</td>\n",
       "      <td>71232.784464</td>\n",
       "      <td>28879.056266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727775</th>\n",
       "      <td>1609372740</td>\n",
       "      <td>28910.54</td>\n",
       "      <td>28911.52</td>\n",
       "      <td>28867.60</td>\n",
       "      <td>28881.30</td>\n",
       "      <td>7.332773</td>\n",
       "      <td>211870.912660</td>\n",
       "      <td>28893.695831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727776</th>\n",
       "      <td>1609372800</td>\n",
       "      <td>28893.21</td>\n",
       "      <td>28928.49</td>\n",
       "      <td>28893.21</td>\n",
       "      <td>28928.49</td>\n",
       "      <td>5.757679</td>\n",
       "      <td>166449.709320</td>\n",
       "      <td>28909.166061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4727777 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Timestamp      Open      High       Low     Close  Volume_(BTC)  \\\n",
       "0        1325317920      4.39      4.39      4.39      4.39      0.455581   \n",
       "1        1325317980       NaN       NaN       NaN       NaN           NaN   \n",
       "2        1325318040       NaN       NaN       NaN       NaN           NaN   \n",
       "3        1325318100       NaN       NaN       NaN       NaN           NaN   \n",
       "4        1325318160       NaN       NaN       NaN       NaN           NaN   \n",
       "...             ...       ...       ...       ...       ...           ...   \n",
       "4727772  1609372560  28801.47  28829.42  28785.64  28829.42      0.965221   \n",
       "4727773  1609372620  28829.42  28863.90  28829.42  28857.06      2.368831   \n",
       "4727774  1609372680  28850.49  28900.52  28850.49  28882.82      2.466590   \n",
       "4727775  1609372740  28910.54  28911.52  28867.60  28881.30      7.332773   \n",
       "4727776  1609372800  28893.21  28928.49  28893.21  28928.49      5.757679   \n",
       "\n",
       "         Volume_(Currency)  Weighted_Price  \n",
       "0                 2.000000        4.390000  \n",
       "1                      NaN             NaN  \n",
       "2                      NaN             NaN  \n",
       "3                      NaN             NaN  \n",
       "4                      NaN             NaN  \n",
       "...                    ...             ...  \n",
       "4727772       27804.572129    28806.429798  \n",
       "4727773       68332.350629    28846.441863  \n",
       "4727774       71232.784464    28879.056266  \n",
       "4727775      211870.912660    28893.695831  \n",
       "4727776      166449.709320    28909.166061  \n",
       "\n",
       "[4727777 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-gibraltar",
   "metadata": {},
   "source": [
    "# Nan's exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-agent",
   "metadata": {},
   "source": [
    "To be continued !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-drilling",
   "metadata": {},
   "source": [
    "# Preprocessing, input data, Model, Cross Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "earned-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"method to get the training data (or a portion of it) from google cloud bucket\"\"\"\n",
    "    # client = storage.Client()\n",
    "    # data = pd.read_csv(f\"gs://{BUCKET_NAME}/{BUCKET_TRAIN_DATA_PATH}\")\n",
    "    data = pd.read_csv('../../raw_data/bitstampUSD.csv')\n",
    "    # data = pd.read_csv('gs://bitcoin-prediction-01/data/bitstampUSD.csv')\n",
    "    data = data[2798176:4727776].copy()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "middle-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_date(data, date_start, date_end):\n",
    "    \n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s', origin='unix')\n",
    "    data = data[['Open', 'Timestamp']].set_index(\"Timestamp\").fillna(method='ffill')\n",
    "    \n",
    "    if date_start != None:\n",
    "        if date_end != None:\n",
    "            data = data[date_start:date_end].copy()\n",
    "    else:\n",
    "        data = data.copy()\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_data(data, \"2020-8-1\", \"2020-10-2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "smart-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data, features_size, h):\n",
    "        \n",
    "    data_pp = data.copy()\n",
    "    data_pp['diff_Open'] = data_pp['Open'].diff(h)\n",
    "    data_pp['diff_Open'] = data_pp['diff_Open'].dropna()\n",
    "    data_pp[f\"t+{h}\"] = data_pp['diff_Open'].shift(-h)\n",
    "    \n",
    "    for i in range(0, features_size):\n",
    "        data_pp[f't-{i}'] = data_pp['Open'].shift(i)\n",
    "    data_shifted = data_pp.dropna()\n",
    "    \n",
    "    return data_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "decreased-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_data(data, 50, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "floral-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_target(data_shifted, h):\n",
    "    \n",
    "    X = data_shifted.drop(columns=['Open', 'diff_Open', f\"t+{h}\"])\n",
    "    y = data_shifted[f\"t+{h}\"].copy()\n",
    "    y[y > 0] = 1\n",
    "    y[y <= 0] = 0\n",
    "    \n",
    "    data_size = data_shifted.shape[0]\n",
    "    \n",
    "    return X, y, data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "greater-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(X, y, sample_size, train_fraction, features_size, data_size, train_size, test_size, h=1, w=0):    \n",
    " \n",
    "\n",
    "    sample_X = X.iloc[data_size-(test_size * w + sample_size) : data_size - (test_size * w)]\n",
    "    sample_y = y.iloc[data_size-(test_size * w + sample_size) : data_size - (test_size * w)]\n",
    "    \n",
    "    X_train = sample_X.iloc[0:train_size]\n",
    "    y_train = sample_y.iloc[0:train_size]\n",
    "    X_test = sample_X.iloc[(train_size+h-1):(sample_size)]\n",
    "    y_test = sample_y.iloc[(train_size+h-1):(sample_size)]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(model_init, X_train, X_test, y_train, y_test):\n",
    "    model = model_init\n",
    "    model = model.fit(X_train, y_train)\n",
    "    results = model.predict(X_test)\n",
    "    score = model.score(X_test, y_test) \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model_init=RidgeClassifier(), sample_size=1000, train_fraction=0.7, features_size=60, h=1, date_start=None, date_end=None):\n",
    "    \n",
    "    data = get_data()\n",
    "#     data = select_date(data, date_start, date_end)\n",
    "#     data_shifted = preprocessing_data(data, features_size, h)\n",
    "#     X, y, data_size = features_target(data_shifted, h)\n",
    "#     train_size = int(train_fraction*sample_size)\n",
    "#     test_size = sample_size - train_size\n",
    "    \n",
    "    \n",
    "#     r = math.floor((data_size-train_size)/test_size)\n",
    "#     intervals = range(0, r)\n",
    "#     reversed_intervals = reversed(intervals)\n",
    "#     results = []\n",
    "    \n",
    "#     for i in reversed_intervals:\n",
    "#         X_train, X_test, y_train, y_test = input_data(X, y, sample_size, train_fraction, features_size, data_size, train_size, test_size, h, w=i)\n",
    "#         score = predict_score(model_init, X_train, X_test, y_train, y_test)\n",
    "#         results.append(score)\n",
    "    \n",
    "    return data\n",
    "#     return dict({'mean_score':round(stats.mean(results),2), 'std':round(stats.stdev(results),2) , 'score_min':round(min(results),2), 'score_max':round(max(results),2)})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val(model_init=RidgeClassifier(), sample_size=1000, train_fraction=0.7, features_size=60, h=1, date_start=None, date_end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "60*24*30*44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1900800-700)/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "((60*24*7)-700)/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val(model_init=RidgeClassifier(), sample_size=1000, train_fraction=0.7, features_size=60, h=1, date_start=None, date_end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val(model_init=RidgeClassifier(), sample_size=1000, train_fraction=0.7, features_size=60, h=1, date_start=None, date_end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val(model_init=RidgeClassifier(), sample_size=1000, train_fraction=0.7, features_size=60, h=30, date_start=None, date_end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val(model_init=RidgeClassifier(), sample_size=1440, train_fraction=0.7, features_size=60, h=10, date_start=None, date_end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val(model_init=RidgeClassifier(), sample_size=1440, train_fraction=0.7, features_size=60, h=5, date_start=None, date_end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val(model_init=RidgeClassifier(), sample_size=1440, train_fraction=0.7, features_size=60, h=2, date_start=None, date_end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "former-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "checked-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(layers.SimpleRNN(units=1, activation='tanh')) # we'll look at units number later\n",
    "# model.add(layers.Dense(1, activation=\"relu\"))\n",
    "\n",
    "# # The compilation\n",
    "# model.compile(loss='mse', \n",
    "#               optimizer='rmsprop')\n",
    "\n",
    "# # The fit\n",
    "# model.fit(X, y,\n",
    "#          batch_size=16,\n",
    "#          epochs=10, verbose=0)\n",
    "\n",
    "# # The prediction\n",
    "# model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Xy(sample_size=1000, train_fraction=0.7, features_size=60, h=1, w=0, RNN=False, date_start=None, date_end=None):\n",
    "    \n",
    "    data = get_data()\n",
    "    data = select_date(data, date_start, date_end)\n",
    "    data_shifted = preprocessing_data(data, features_size, h)\n",
    "    X, y, data_size = features_target(data_shifted, h)\n",
    "    train_size = int(train_fraction*sample_size)\n",
    "    test_size = sample_size - train_size\n",
    "    X_train, X_test, y_train, y_test = input_data(X, y, sample_size, train_fraction, features_size, data_size, train_size, test_size, h, w)\n",
    "    \n",
    "    if RNN == True:\n",
    "        X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "        X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = test_Xy(sample_size=1440, train_fraction=0.7, features_size=60, h=2, w=0, RNN=True, date_start=None, date_end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(10, activation='tanh'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Adding the first LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "# Adding the output layer\n",
    "model.add(Dense(units = 1))\n",
    "# Compiling the RNN\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fitting the RNN to the Training set\n",
    "model.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(100, activation='tanh'))\n",
    "# model.add(Dense(50, activation='tanh'))\n",
    "# model.add(Dense(10, activation='tanh'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Adding the first LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 40, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 30, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 15))\n",
    "model.add(Dropout(0.2))\n",
    "# Adding the output layer\n",
    "model.add(Dense(units = 1))\n",
    "# Compiling the RNN\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fitting the RNN to the Training set\n",
    "model.fit(X_train, y_train, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "\n",
    "# model.fit(X_train, y_train, \n",
    "#           batch_size=16, \n",
    "#           epochs=1000, \n",
    "#           validation_split=0.3,\n",
    "#           callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "settled-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score_deep(model_deep, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    model = Sequential()\n",
    "    es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "    \n",
    "    if model_deep == LSTM:\n",
    "        model.add(LSTM(units = 30, activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "        model.add(Dropout(0.2))\n",
    "#         model.add(LSTM(units = 40, return_sequences = True))\n",
    "#         model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units = 10,  activation='tanh', return_sequences = True))\n",
    "        model.add(Dropout(0.2))\n",
    "        # Adding the output layer\n",
    "        model.add(Dense(units = 5, activation='relu'))\n",
    "        model.add(Dense(units = 1, activation='sigmoid'))\n",
    "        # Compiling the RNN\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        # Fitting the RNN to the Training set\n",
    "        model.fit(X_train, y_train, validation_split=0.2, epochs = 100, batch_size = 32, callbacks=[es])\n",
    "\n",
    "        score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    if model_deep == GRU:\n",
    "        pass\n",
    "        \n",
    "    return score[1] #attention score[0] loss à return also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def deep_test_b(model_deep, sample_size=1000, train_fraction=0.7, features_size=60, h=1, RNN=True, date_start=None, date_end=None):\n",
    "    \n",
    "#     data = get_data()\n",
    "#     data = select_date(data, date_start, date_end)\n",
    "#     data_shifted = preprocessing_data(data, features_size, h)\n",
    "#     X, y, data_size = features_target(data_shifted, h)\n",
    "#     train_size = int(train_fraction*sample_size)\n",
    "#     test_size = sample_size - train_size\n",
    "    \n",
    "#     if RNN == True:\n",
    "#             X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "#             X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "#             X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "#             X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "\n",
    "#     X_train, X_test, y_train, y_test = input_data(X, y, sample_size, train_fraction, features_size, data_size, train_size, test_size, h, w=0)\n",
    "\n",
    "    \n",
    "#     return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "1440*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = deep_test_b(LSTM, sample_size=100, train_fraction=0.7, features_size=50, h=5, RNN=True, date_start=\"2020\", date_end=\"2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-dress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = deep_test_b(LSTM, sample_size=10080, train_fraction=0.7, features_size=21600, h=1440, RNN=True, date_start=\"2020\", date_end=\"2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units = 30, activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units = 10,  activation='tanh', return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 5, activation='relu'))\n",
    "model.add(Dense(units = 1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "preliminary-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_test(model_deep, sample_size=1000, train_fraction=0.7, features_size=60, h=1, RNN=True, date_start=None, date_end=None):\n",
    "    \n",
    "    data = get_data()\n",
    "    data = select_date(data, date_start, date_end)\n",
    "    data_shifted = preprocessing_data(data, features_size, h)\n",
    "    X, y, data_size = features_target(data_shifted, h)\n",
    "    train_size = int(train_fraction*sample_size)\n",
    "    test_size = sample_size - train_size\n",
    "    \n",
    "    r = math.floor((data_size-train_size)/test_size)\n",
    "    intervals = range(0, r)\n",
    "    reversed_intervals = reversed(intervals)\n",
    "    results = []\n",
    "    \n",
    "    for i in reversed_intervals:\n",
    "        X_train, X_test, y_train, y_test = input_data(X, y, sample_size, train_fraction, features_size, data_size, train_size, test_size, h, w=i)\n",
    "        \n",
    "        if RNN == True:\n",
    "            X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "            X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "            X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "            X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "            \n",
    "        score = predict_score_deep(model_deep, X_train, X_test, y_train, y_test)\n",
    "        results.append(score)\n",
    "    \n",
    "    return dict({'mean_score':round(stats.mean(results),2),\n",
    "                 'std':round(stats.stdev(results),2),\n",
    "                 'score_min':round(min(results),2),\n",
    "                 'score_max':round(max(results),2),\n",
    "                 'n_fold':r})\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "1440*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "recognized-reconstruction",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.09 GiB for an array with shape (1301, 525600) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/bitcoin/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 't-1297'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/bitcoin/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3824\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3825\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3826\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/bitcoin/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 't-1297'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-75638b4f9c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeep_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m43200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1440\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2020\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2020\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-2ca766da7c3e>\u001b[0m in \u001b[0;36mdeep_test\u001b[0;34m(model_deep, sample_size, train_fraction, features_size, h, RNN, date_start, date_end)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata_shifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shifted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_fraction\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-755c34374b8f>\u001b[0m in \u001b[0;36mpreprocessing_data\u001b[0;34m(data, features_size, h)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdata_pp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf't-{i}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_pp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdata_shifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_pp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/bitcoin/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/bitcoin/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3239\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3240\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3242\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/bitcoin/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3826\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3827\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3828\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3829\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/bitcoin/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m     def reindex_axis(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/bitcoin/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/bitcoin/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   1914\u001b[0m     \u001b[0mnew_blocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m         merged_blocks = _merge_blocks(\n\u001b[0m\u001b[1;32m   1917\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_consolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m         )\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/bitcoin/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[1;32m   1940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1942\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1943\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 5.09 GiB for an array with shape (1301, 525600) and data type float64"
     ]
    }
   ],
   "source": [
    "deep_test(LSTM, sample_size=43200, train_fraction=0.7, features_size=21600, h=1440, RNN=True, date_start=\"2020\", date_end=\"2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_test(LSTM, sample_size=1440, train_fraction=0.7, features_size=60, h=10, w=0, RNN=True, date_start=\"2020-01-01\", date_end=\"2020-02-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook résultats\n",
    "d-tale\n",
    "recuperer données mlflow, filtre\n",
    "deep\n",
    "tester modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-handy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "# modeldeep_2 = KerasClassifier(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val(model_init=modeldeep, sample_size=1440, train_fraction=0.7, features_size=60, h=2, date_start=None, date_end=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
